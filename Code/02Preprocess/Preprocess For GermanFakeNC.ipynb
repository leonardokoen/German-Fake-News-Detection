{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "823c69c0",
   "metadata": {},
   "source": [
    "# Preprocess for GermanFakeNC dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adc6f70",
   "metadata": {},
   "source": [
    "# Import necessary libraries  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6accbc52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk \n",
    "import re \n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd7d506",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce3f4bd",
   "metadata": {},
   "source": [
    "## Loading GermanFakeNC.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24391aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>URL</th>\n",
       "      <th>False_Statement_1_Location</th>\n",
       "      <th>False_Statement_1_Index</th>\n",
       "      <th>False_Statement_2_Location</th>\n",
       "      <th>False_Statement_2_Index</th>\n",
       "      <th>False_Statement_3_Location</th>\n",
       "      <th>False_Statement_3_Index</th>\n",
       "      <th>Ratio_of_Fake_Statements</th>\n",
       "      <th>Overall_Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-08-30</td>\n",
       "      <td>https://schluesselkindblog.com/2017/08/30/proz...</td>\n",
       "      <td>Text</td>\n",
       "      <td>213-237</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-12-18</td>\n",
       "      <td>http://blauerbote.com/2017/12/18/bild-journali...</td>\n",
       "      <td>Text</td>\n",
       "      <td>13-36</td>\n",
       "      <td>Text</td>\n",
       "      <td>52-81</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-06-02</td>\n",
       "      <td>http://blauerbote.com/2017/06/02/angela-merkel...</td>\n",
       "      <td>Title</td>\n",
       "      <td>1-7</td>\n",
       "      <td>Text</td>\n",
       "      <td>70-94</td>\n",
       "      <td>Text</td>\n",
       "      <td>121-153</td>\n",
       "      <td>3</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-09-25</td>\n",
       "      <td>http://smopo.ch/deutschlands-neonazis-waehlen-...</td>\n",
       "      <td>Title</td>\n",
       "      <td>1-5</td>\n",
       "      <td>Text</td>\n",
       "      <td>28-53</td>\n",
       "      <td>Text</td>\n",
       "      <td>127-141</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-02-17</td>\n",
       "      <td>http://www.truth24.net/gruppenvergewaltigung-s...</td>\n",
       "      <td>Title</td>\n",
       "      <td>1-1</td>\n",
       "      <td>Title</td>\n",
       "      <td>3-4</td>\n",
       "      <td>Title</td>\n",
       "      <td>6-7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>http://www.anonymousnews.ru/2017/11/01/sex-dsc...</td>\n",
       "      <td>Image</td>\n",
       "      <td></td>\n",
       "      <td>Image</td>\n",
       "      <td></td>\n",
       "      <td>Image</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>2017-11-17</td>\n",
       "      <td>https://blog.halle-leaks.de/messer-jihad-in-ko...</td>\n",
       "      <td>Title</td>\n",
       "      <td>1-10</td>\n",
       "      <td>Image</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>2017-10-29</td>\n",
       "      <td>https://blog.halle-leaks.de/erzieherin-will-vo...</td>\n",
       "      <td>Title</td>\n",
       "      <td>1-12</td>\n",
       "      <td>Text</td>\n",
       "      <td>1-32</td>\n",
       "      <td>Text</td>\n",
       "      <td>1-32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>2017-12-30</td>\n",
       "      <td>https://www.compact-online.de/armer-martin-sch...</td>\n",
       "      <td>Text</td>\n",
       "      <td>132-142</td>\n",
       "      <td>Text</td>\n",
       "      <td>143-169</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>2018-02-24</td>\n",
       "      <td>https://de.sott.net/article/32263-Kindesmissbr...</td>\n",
       "      <td>Title</td>\n",
       "      <td>1-12</td>\n",
       "      <td>Text</td>\n",
       "      <td>50-111</td>\n",
       "      <td>Text</td>\n",
       "      <td>557-591</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>490 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date                                                URL  \\\n",
       "0   2017-08-30  https://schluesselkindblog.com/2017/08/30/proz...   \n",
       "1   2017-12-18  http://blauerbote.com/2017/12/18/bild-journali...   \n",
       "2   2017-06-02  http://blauerbote.com/2017/06/02/angela-merkel...   \n",
       "3   2017-09-25  http://smopo.ch/deutschlands-neonazis-waehlen-...   \n",
       "4   2018-02-17  http://www.truth24.net/gruppenvergewaltigung-s...   \n",
       "..         ...                                                ...   \n",
       "485 2017-11-01  http://www.anonymousnews.ru/2017/11/01/sex-dsc...   \n",
       "486 2017-11-17  https://blog.halle-leaks.de/messer-jihad-in-ko...   \n",
       "487 2017-10-29  https://blog.halle-leaks.de/erzieherin-will-vo...   \n",
       "488 2017-12-30  https://www.compact-online.de/armer-martin-sch...   \n",
       "489 2018-02-24  https://de.sott.net/article/32263-Kindesmissbr...   \n",
       "\n",
       "    False_Statement_1_Location False_Statement_1_Index  \\\n",
       "0                         Text                 213-237   \n",
       "1                         Text                   13-36   \n",
       "2                        Title                     1-7   \n",
       "3                        Title                     1-5   \n",
       "4                        Title                     1-1   \n",
       "..                         ...                     ...   \n",
       "485                      Image                           \n",
       "486                      Title                    1-10   \n",
       "487                      Title                    1-12   \n",
       "488                       Text                 132-142   \n",
       "489                      Title                    1-12   \n",
       "\n",
       "    False_Statement_2_Location False_Statement_2_Index  \\\n",
       "0                                                        \n",
       "1                         Text                   52-81   \n",
       "2                         Text                   70-94   \n",
       "3                         Text                   28-53   \n",
       "4                        Title                     3-4   \n",
       "..                         ...                     ...   \n",
       "485                      Image                           \n",
       "486                      Image                           \n",
       "487                       Text                    1-32   \n",
       "488                       Text                 143-169   \n",
       "489                       Text                  50-111   \n",
       "\n",
       "    False_Statement_3_Location False_Statement_3_Index  \\\n",
       "0                                                        \n",
       "1                                                        \n",
       "2                         Text                 121-153   \n",
       "3                         Text                 127-141   \n",
       "4                        Title                     6-7   \n",
       "..                         ...                     ...   \n",
       "485                      Image                           \n",
       "486                                                      \n",
       "487                       Text                    1-32   \n",
       "488                                                      \n",
       "489                       Text                 557-591   \n",
       "\n",
       "     Ratio_of_Fake_Statements  Overall_Rating  \n",
       "0                           1             0.7  \n",
       "1                           3             0.8  \n",
       "2                           3             0.7  \n",
       "3                           3             0.8  \n",
       "4                           1             0.4  \n",
       "..                        ...             ...  \n",
       "485                         3             0.8  \n",
       "486                         1             0.7  \n",
       "487                         2             0.8  \n",
       "488                         1             0.4  \n",
       "489                         2             0.7  \n",
       "\n",
       "[490 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('../../Datasets/GermanFakeNC/GermanFakeNC.json')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583382be",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d91185d",
   "metadata": {},
   "source": [
    "We used a German stemmer we found on github: https://github.com/LeonieWeissweiler/CISTEM  \n",
    "And we created a function named stemmer that performs German stopword removal and stemming in a dataset entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d5ac0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stripge = re.compile(r\"^ge(.{4,})\")\n",
    "replxx = re.compile(r\"(.)\\1\")\n",
    "replxxback = re.compile(r\"(.)\\*\");\n",
    "stripemr = re.compile(r\"e[mr]$\")\n",
    "stripnd = re.compile(r\"nd$\")\n",
    "stript = re.compile(r\"t$\")\n",
    "stripesn = re.compile(r\"[esn]$\")\n",
    "\n",
    "\n",
    "def stem(word, case_insensitive = False):\n",
    "    if len(word) == 0:\n",
    "        return word\n",
    "\n",
    "    upper = word[0].isupper()\n",
    "    word = word.lower()\n",
    "\n",
    "    word = word.replace(\"Ã¼\",\"u\")\n",
    "    word = word.replace(\"Ã¶\",\"o\")\n",
    "    word = word.replace(\"Ã¤\",\"a\")\n",
    "    word = word.replace(\"ÃŸ\",\"ss\")\n",
    "\n",
    "    word = stripge.sub(r\"\\1\", word)\n",
    "    word = word.replace(\"sch\",\"$\")\n",
    "    word = word.replace(\"ei\",\"%\")\n",
    "    word = word.replace(\"ie\",\"&\")\n",
    "    word = replxx.sub(r\"\\1*\", word)\n",
    "\n",
    "    while len(word) > 3:\n",
    "        if len(word) > 5:\n",
    "            (word, success) = stripemr.subn(\"\", word)\n",
    "            if success != 0:\n",
    "                continue\n",
    "\n",
    "            (word, success) = stripnd.subn(\"\", word)\n",
    "            if success != 0:\n",
    "                continue\n",
    "\n",
    "        if not upper or case_insensitive:\n",
    "            (word, success) = stript.subn(\"\", word)\n",
    "            if success != 0:\n",
    "                continue\n",
    "\n",
    "        (word, success) = stripesn.subn(\"\", word)\n",
    "        if success != 0:\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    word = replxxback.sub(r\"\\1\\1\", word)\n",
    "    word = word.replace(\"%\",\"ei\")\n",
    "    word = word.replace(\"&\",\"ie\")\n",
    "    word = word.replace(\"$\",\"sch\")\n",
    "\n",
    "    return word\n",
    "\n",
    "def stemmer(title):\n",
    "    review = re.sub('[^a-zA-ZÃ¤Ã¶Ã¼Ã„Ã–ÃœÃŸ]',' ', title)\n",
    "    review = review.lower().split()\n",
    "    review = [stem(word) for word in review if not word in stopwords.words('german')]\n",
    "    review = ' '.join(review)\n",
    "    return(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd093b92",
   "metadata": {},
   "source": [
    "## Web Scraping and Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65405f88",
   "metadata": {},
   "source": [
    "We created a function that takes as input our dataframe and scrapes the title and the body of each article in the dataset if the access is not forbidden. It also performs stemming and stop word removal at each entry. Finally it classifies the data to 0(Real) or 1(Fake) depending on their Overall_Rating and the threshold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7519d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_fake_news(df, thresshold):\n",
    "    titles = list()\n",
    "    texts = list()\n",
    "    scores = list()\n",
    "    \n",
    "    #Scraping\n",
    "    for i in range(0, len(df)):\n",
    "        try:\n",
    "            page=requests.get(df['URL'][i]) \n",
    "        except Exception as e:       \n",
    "            continue\n",
    "        coverpage = page.content\n",
    "        \n",
    "        soup = BeautifulSoup(coverpage, 'html5lib')\n",
    "        title = soup.find('title')\n",
    "        if title is not None:\n",
    "            title = soup.title.get_text()\n",
    "    #Stemming and stopword removal         \n",
    "        text = soup.body.get_text()\n",
    "        if title is not None:\n",
    "            title = stemmer(title)\n",
    "        text = stemmer(text)\n",
    "        \n",
    "        titles.append(title)\n",
    "        texts.append(text)\n",
    "        if df['Overall_Rating'][i] <= thresshold:\n",
    "            scores.append(0)\n",
    "        else:\n",
    "            scores.append(1)\n",
    "    \n",
    "    #Creating final dataframe and removing access forbidden websites\n",
    "    df = pd.DataFrame(list(zip(titles, texts, scores)), columns = ['Title', 'Text', 'Fake-Real'])\n",
    "    for i in range(0, len(df)):\n",
    "        if df['Title'][i] == \"forbidd\":\n",
    "            df = df.drop(i)\n",
    "        \n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    for i in range(0, len(df)):\n",
    "        if pd.isna(df['Title'][i]):\n",
    "            df = df.drop(i)\n",
    "        \n",
    "    df = df.reset_index(drop=True)  \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97a6199",
   "metadata": {},
   "source": [
    "## Creating new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2908d23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed = create_dataset_fake_news(df, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fa760820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "      <th>Fake-Real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bild journali julia ropck nazifreu blau bot ma...</td>\n",
       "      <td>inhal spring blau bot magazi wissenschaf statt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>angela merkel lass rock ring abbrech blau bot ...</td>\n",
       "      <td>inhal spring blau bot magazi wissenschaf statt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gruppenvergewaltigung sex jihadi vergewaltig j...</td>\n",
       "      <td>such hom tagesschau truth original meld abou u...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ozapf is turk versuch koreaneri wies vergewalt...</td>\n",
       "      <td>vergewaltigung asyla fluchtling migra rapefuge...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>katalonie tag diktatur spanisch zentralstaa un...</td>\n",
       "      <td>katalonie tag diktatur spanisch zentralstaa un...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>mehr sexattack armutsasyla uberfall frau krefe...</td>\n",
       "      <td>such hom tagesschau truth original meld abou u...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>komm egal erzahl deutsch regierung berei umstr...</td>\n",
       "      <td>inhal spring fr feb th guido grand publizi aut...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>amtlich meis terrori komm afghanista somalia s...</td>\n",
       "      <td>inhal spring fr feb th guido grand publizi aut...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>sex dschihad ess fluchtling sturm hallowee par...</td>\n",
       "      <td>deutschlandinternationalmeinunghintergrundemed...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>kindesmissbrauch fall padophil prie fangni ste...</td>\n",
       "      <td>willkomm sott net fr feb wel mensch denk kateg...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>307 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title  \\\n",
       "0    bild journali julia ropck nazifreu blau bot ma...   \n",
       "1    angela merkel lass rock ring abbrech blau bot ...   \n",
       "2    gruppenvergewaltigung sex jihadi vergewaltig j...   \n",
       "3    ozapf is turk versuch koreaneri wies vergewalt...   \n",
       "4    katalonie tag diktatur spanisch zentralstaa un...   \n",
       "..                                                 ...   \n",
       "302  mehr sexattack armutsasyla uberfall frau krefe...   \n",
       "303  komm egal erzahl deutsch regierung berei umstr...   \n",
       "304  amtlich meis terrori komm afghanista somalia s...   \n",
       "305  sex dschihad ess fluchtling sturm hallowee par...   \n",
       "306  kindesmissbrauch fall padophil prie fangni ste...   \n",
       "\n",
       "                                                  Text  Fake-Real  \n",
       "0    inhal spring blau bot magazi wissenschaf statt...          1  \n",
       "1    inhal spring blau bot magazi wissenschaf statt...          1  \n",
       "2    such hom tagesschau truth original meld abou u...          1  \n",
       "3    vergewaltigung asyla fluchtling migra rapefuge...          1  \n",
       "4    katalonie tag diktatur spanisch zentralstaa un...          1  \n",
       "..                                                 ...        ...  \n",
       "302  such hom tagesschau truth original meld abou u...          1  \n",
       "303  inhal spring fr feb th guido grand publizi aut...          1  \n",
       "304  inhal spring fr feb th guido grand publizi aut...          1  \n",
       "305  deutschlandinternationalmeinunghintergrundemed...          1  \n",
       "306  willkomm sott net fr feb wel mensch denk kateg...          1  \n",
       "\n",
       "[307 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9a3b63",
   "metadata": {},
   "source": [
    "   ## Saving our dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "453e5f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some statistics about our data\n",
    "print(\"Real\\n\",df_preprocessed[df_preprocessed['Fake-Real'] == 0].count())\n",
    "print(\"Fake\\n\",df_preprocessed[df_preprocessed['Fake-Real'] == 1].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a854690b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake-Real    77\n",
      "dtype: int64\n",
      "Fake-Real    236\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_preprocessed.to_csv('../../Datasets/GermanFakeNC/df_preprocessed_GermanFakeNC')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
